{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, random\n",
    "import keras\n",
    "from keras.datasets import fashion_mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, BatchNormalization, Dropout\n",
    "from keras.utils import np_utils\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "os.path.expanduser = lambda path: './'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
      "32768/29515 [=================================] - 0s 0us/step\n",
      "40960/29515 [=========================================] - 0s 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
      "26427392/26421880 [==============================] - 26s 1us/step\n",
      "26435584/26421880 [==============================] - 26s 1us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
      "16384/5148 [===============================================================================================] - 0s 0s/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
      "4423680/4422102 [==============================] - 3s 1us/step\n",
      "4431872/4422102 [==============================] - 3s 1us/step\n",
      "60000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 60\n",
    "\n",
    "# the data, split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
    "\n",
    "x_train = x_train.reshape(60000, 784)\n",
    "x_test = x_test.reshape(10000, 784)\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.np_utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.np_utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 512)               401920    \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 512)               0         \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 512)              2048      \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 512)               262656    \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 512)              2048      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 673,802\n",
      "Trainable params: 671,754\n",
      "Non-trainable params: 2,048\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_3 (Dense)             (None, 512)               401920    \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 512)              2048      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 512)               262656    \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 512)              2048      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 673,802\n",
      "Trainable params: 671,754\n",
      "Non-trainable params: 2,048\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_6 (Dense)             (None, 512)               401920    \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 512)              2048      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 512)               262656    \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " batch_normalization_5 (Batc  (None, 512)              2048      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 673,802\n",
      "Trainable params: 671,754\n",
      "Non-trainable params: 2,048\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# for reproducibility\n",
    "import random, os\n",
    "os.environ['PYTHONHASHSEED']='0'\n",
    "random.seed(123)\n",
    "np.random.seed(123)\n",
    "tf.random.set_seed(123)\n",
    "sess = tf.compat.v1.Session(config=tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1,    inter_op_parallelism_threads=1,\n",
    "                                                               allow_soft_placement=True, device_count = {'CPU': 1}))\n",
    "from tensorflow.python.keras import backend as K\n",
    "K.set_session(sess)\n",
    "\n",
    "\n",
    "\n",
    "kernel_initializer='glorot_uniform'\n",
    "activation_function = 'relu'\n",
    "\n",
    "with tf.device('/cpu:0'):\n",
    "    model1 = Sequential()\n",
    "    model1.add(Dense(512, activation='relu', input_shape=(784,)))\n",
    "    model1.add(Dropout(0.2))\n",
    "    model1.add(BatchNormalization())\n",
    "    #model.add(BatchNormalization())\n",
    "    model1.add(Dense(512, activation='relu'))\n",
    "    model1.add(Dropout(0.2))\n",
    "    model1.add(BatchNormalization())\n",
    "    #model.add(BatchNormalization())\n",
    "    model1.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    model1.summary()\n",
    "\n",
    "    model1.compile(loss='categorical_crossentropy',\n",
    "                  optimizer='sgd',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "with tf.device('/cpu:0'):\n",
    "    model2 = Sequential()\n",
    "    model2.add(Dense(512, activation='relu', input_shape=(784,)))\n",
    "    model2.add(Dropout(0.5))\n",
    "    model2.add(BatchNormalization())\n",
    "    #model.add(BatchNormalization())\n",
    "    model2.add(Dense(512, activation='relu'))\n",
    "    model2.add(Dropout(0.5))\n",
    "    model2.add(BatchNormalization())\n",
    "    #model.add(BatchNormalization())\n",
    "    model2.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    model2.summary()\n",
    "\n",
    "    model2.compile(loss='categorical_crossentropy',\n",
    "                  optimizer='sgd',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "with tf.device('/cpu:0'):\n",
    "    model3 = Sequential()\n",
    "    model3.add(Dense(512, activation='relu', input_shape=(784,)))\n",
    "    model3.add(Dropout(0.8))\n",
    "    model3.add(BatchNormalization())\n",
    "    #model.add(BatchNormalization())\n",
    "    model3.add(Dense(512, activation='relu'))\n",
    "    model3.add(Dropout(0.8))\n",
    "    model3.add(BatchNormalization())\n",
    "    #model.add(BatchNormalization())\n",
    "    model3.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    model3.summary()\n",
    "\n",
    "    model3.compile(loss='categorical_crossentropy',\n",
    "                  optimizer='sgd',\n",
    "                  metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "375/375 [==============================] - 6s 13ms/step - loss: 0.7245 - accuracy: 0.7482 - val_loss: 0.5082 - val_accuracy: 0.8239\n",
      "Epoch 2/60\n",
      "375/375 [==============================] - 5s 12ms/step - loss: 0.5070 - accuracy: 0.8203 - val_loss: 0.4156 - val_accuracy: 0.8523\n",
      "Epoch 3/60\n",
      "375/375 [==============================] - 5s 12ms/step - loss: 0.4549 - accuracy: 0.8367 - val_loss: 0.3872 - val_accuracy: 0.8632\n",
      "Epoch 4/60\n",
      "375/375 [==============================] - 5s 12ms/step - loss: 0.4216 - accuracy: 0.8502 - val_loss: 0.3709 - val_accuracy: 0.8679\n",
      "Epoch 5/60\n",
      "375/375 [==============================] - 5s 12ms/step - loss: 0.4020 - accuracy: 0.8548 - val_loss: 0.3603 - val_accuracy: 0.8708\n",
      "Epoch 6/60\n",
      "375/375 [==============================] - 5s 12ms/step - loss: 0.3843 - accuracy: 0.8631 - val_loss: 0.3507 - val_accuracy: 0.8734\n",
      "Epoch 7/60\n",
      "375/375 [==============================] - 5s 12ms/step - loss: 0.3688 - accuracy: 0.8688 - val_loss: 0.3440 - val_accuracy: 0.8763\n",
      "Epoch 8/60\n",
      "375/375 [==============================] - 4s 12ms/step - loss: 0.3567 - accuracy: 0.8698 - val_loss: 0.3458 - val_accuracy: 0.8767\n",
      "Epoch 9/60\n",
      "375/375 [==============================] - 4s 12ms/step - loss: 0.3456 - accuracy: 0.8742 - val_loss: 0.3358 - val_accuracy: 0.8799\n",
      "Epoch 10/60\n",
      "375/375 [==============================] - 5s 12ms/step - loss: 0.3366 - accuracy: 0.8773 - val_loss: 0.3261 - val_accuracy: 0.8823\n",
      "Epoch 11/60\n",
      "375/375 [==============================] - 5s 12ms/step - loss: 0.3302 - accuracy: 0.8785 - val_loss: 0.3315 - val_accuracy: 0.8788\n",
      "Epoch 12/60\n",
      "375/375 [==============================] - 5s 12ms/step - loss: 0.3192 - accuracy: 0.8832 - val_loss: 0.3235 - val_accuracy: 0.8849\n",
      "Epoch 13/60\n",
      "375/375 [==============================] - 5s 12ms/step - loss: 0.3104 - accuracy: 0.8864 - val_loss: 0.3217 - val_accuracy: 0.8842\n",
      "Epoch 14/60\n",
      "375/375 [==============================] - 4s 12ms/step - loss: 0.3080 - accuracy: 0.8869 - val_loss: 0.3216 - val_accuracy: 0.8857\n",
      "Epoch 15/60\n",
      "375/375 [==============================] - 4s 12ms/step - loss: 0.2977 - accuracy: 0.8892 - val_loss: 0.3112 - val_accuracy: 0.8859\n",
      "Epoch 16/60\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 0.2948 - accuracy: 0.8911 - val_loss: 0.3136 - val_accuracy: 0.8865\n",
      "Epoch 17/60\n",
      "375/375 [==============================] - 4s 12ms/step - loss: 0.2872 - accuracy: 0.8951 - val_loss: 0.3116 - val_accuracy: 0.8871\n",
      "Epoch 18/60\n",
      "375/375 [==============================] - 4s 12ms/step - loss: 0.2825 - accuracy: 0.8953 - val_loss: 0.3095 - val_accuracy: 0.8883\n",
      "Epoch 19/60\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 0.2780 - accuracy: 0.8988 - val_loss: 0.3102 - val_accuracy: 0.8870\n",
      "Epoch 20/60\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 0.2734 - accuracy: 0.9003 - val_loss: 0.3066 - val_accuracy: 0.8890\n",
      "Epoch 21/60\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 0.2638 - accuracy: 0.9024 - val_loss: 0.3072 - val_accuracy: 0.8889\n",
      "Epoch 22/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.2631 - accuracy: 0.9031 - val_loss: 0.3238 - val_accuracy: 0.8831\n",
      "Epoch 23/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.2585 - accuracy: 0.9053 - val_loss: 0.3040 - val_accuracy: 0.8898\n",
      "Epoch 24/60\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 0.2532 - accuracy: 0.9068 - val_loss: 0.3091 - val_accuracy: 0.8868\n",
      "Epoch 25/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.2493 - accuracy: 0.9070 - val_loss: 0.3044 - val_accuracy: 0.8907\n",
      "Epoch 26/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.2428 - accuracy: 0.9097 - val_loss: 0.3070 - val_accuracy: 0.8890\n",
      "Epoch 27/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.2410 - accuracy: 0.9114 - val_loss: 0.3055 - val_accuracy: 0.8903\n",
      "Epoch 28/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.2365 - accuracy: 0.9137 - val_loss: 0.3087 - val_accuracy: 0.8874\n",
      "Epoch 29/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.2326 - accuracy: 0.9140 - val_loss: 0.3011 - val_accuracy: 0.8932\n",
      "Epoch 30/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.2284 - accuracy: 0.9160 - val_loss: 0.3041 - val_accuracy: 0.8910\n",
      "Epoch 31/60\n",
      "375/375 [==============================] - 4s 12ms/step - loss: 0.2249 - accuracy: 0.9171 - val_loss: 0.3061 - val_accuracy: 0.8901\n",
      "Epoch 32/60\n",
      "375/375 [==============================] - 4s 12ms/step - loss: 0.2208 - accuracy: 0.9182 - val_loss: 0.3043 - val_accuracy: 0.8907\n",
      "Epoch 33/60\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 0.2219 - accuracy: 0.9172 - val_loss: 0.3032 - val_accuracy: 0.8929\n",
      "Epoch 34/60\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 0.2187 - accuracy: 0.9188 - val_loss: 0.3052 - val_accuracy: 0.8928\n",
      "Epoch 35/60\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 0.2116 - accuracy: 0.9205 - val_loss: 0.3072 - val_accuracy: 0.8914\n",
      "Epoch 36/60\n",
      "375/375 [==============================] - 4s 12ms/step - loss: 0.2106 - accuracy: 0.9219 - val_loss: 0.3031 - val_accuracy: 0.8928\n",
      "Epoch 37/60\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 0.2087 - accuracy: 0.9230 - val_loss: 0.3059 - val_accuracy: 0.8905\n",
      "Epoch 38/60\n",
      "375/375 [==============================] - 5s 12ms/step - loss: 0.2064 - accuracy: 0.9234 - val_loss: 0.3071 - val_accuracy: 0.8916\n",
      "Epoch 39/60\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 0.2020 - accuracy: 0.9258 - val_loss: 0.3059 - val_accuracy: 0.8948\n",
      "Epoch 40/60\n",
      "375/375 [==============================] - 4s 12ms/step - loss: 0.2006 - accuracy: 0.9254 - val_loss: 0.3087 - val_accuracy: 0.8905\n",
      "Epoch 41/60\n",
      "375/375 [==============================] - 5s 12ms/step - loss: 0.1973 - accuracy: 0.9277 - val_loss: 0.3054 - val_accuracy: 0.8905\n",
      "Epoch 42/60\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 0.1929 - accuracy: 0.9300 - val_loss: 0.3077 - val_accuracy: 0.8911\n",
      "Epoch 43/60\n",
      "375/375 [==============================] - 5s 12ms/step - loss: 0.1901 - accuracy: 0.9295 - val_loss: 0.3094 - val_accuracy: 0.8904\n",
      "Epoch 44/60\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 0.1881 - accuracy: 0.9293 - val_loss: 0.3123 - val_accuracy: 0.8918\n",
      "Epoch 45/60\n",
      "375/375 [==============================] - 5s 12ms/step - loss: 0.1846 - accuracy: 0.9314 - val_loss: 0.3166 - val_accuracy: 0.8903\n",
      "Epoch 46/60\n",
      "375/375 [==============================] - 5s 12ms/step - loss: 0.1843 - accuracy: 0.9306 - val_loss: 0.3130 - val_accuracy: 0.8921\n",
      "Epoch 47/60\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 0.1797 - accuracy: 0.9329 - val_loss: 0.3076 - val_accuracy: 0.8929\n",
      "Epoch 48/60\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 0.1787 - accuracy: 0.9337 - val_loss: 0.3176 - val_accuracy: 0.8906\n",
      "Epoch 49/60\n",
      "375/375 [==============================] - 5s 12ms/step - loss: 0.1756 - accuracy: 0.9346 - val_loss: 0.3120 - val_accuracy: 0.8928\n",
      "Epoch 50/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.1727 - accuracy: 0.9362 - val_loss: 0.3152 - val_accuracy: 0.8898\n",
      "Epoch 51/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.1724 - accuracy: 0.9370 - val_loss: 0.3156 - val_accuracy: 0.8933\n",
      "Epoch 52/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.1695 - accuracy: 0.9377 - val_loss: 0.3131 - val_accuracy: 0.8914\n",
      "Epoch 53/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.1664 - accuracy: 0.9380 - val_loss: 0.3294 - val_accuracy: 0.8876\n",
      "Epoch 54/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.1640 - accuracy: 0.9392 - val_loss: 0.3121 - val_accuracy: 0.8941\n",
      "Epoch 55/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.1630 - accuracy: 0.9389 - val_loss: 0.3171 - val_accuracy: 0.8923\n",
      "Epoch 56/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.1627 - accuracy: 0.9404 - val_loss: 0.3233 - val_accuracy: 0.8921\n",
      "Epoch 57/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.1571 - accuracy: 0.9420 - val_loss: 0.3163 - val_accuracy: 0.8932\n",
      "Epoch 58/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "375/375 [==============================] - 3s 9ms/step - loss: 0.1577 - accuracy: 0.9415 - val_loss: 0.3279 - val_accuracy: 0.8927\n",
      "Epoch 59/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.1528 - accuracy: 0.9428 - val_loss: 0.3182 - val_accuracy: 0.8928\n",
      "Epoch 60/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.1578 - accuracy: 0.9417 - val_loss: 0.3279 - val_accuracy: 0.8906\n",
      "Epoch 1/60\n",
      "375/375 [==============================] - 4s 9ms/step - loss: 1.0606 - accuracy: 0.6371 - val_loss: 0.5957 - val_accuracy: 0.7953\n",
      "Epoch 2/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.6925 - accuracy: 0.7574 - val_loss: 0.4829 - val_accuracy: 0.8238\n",
      "Epoch 3/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.6104 - accuracy: 0.7846 - val_loss: 0.4550 - val_accuracy: 0.8363\n",
      "Epoch 4/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.5675 - accuracy: 0.7985 - val_loss: 0.4344 - val_accuracy: 0.8443\n",
      "Epoch 5/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.5334 - accuracy: 0.8107 - val_loss: 0.4135 - val_accuracy: 0.8501\n",
      "Epoch 6/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.5117 - accuracy: 0.8188 - val_loss: 0.4051 - val_accuracy: 0.8551\n",
      "Epoch 7/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.4919 - accuracy: 0.8245 - val_loss: 0.4006 - val_accuracy: 0.8562\n",
      "Epoch 8/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.4807 - accuracy: 0.8298 - val_loss: 0.3904 - val_accuracy: 0.8602\n",
      "Epoch 9/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.4638 - accuracy: 0.8337 - val_loss: 0.3889 - val_accuracy: 0.8618\n",
      "Epoch 10/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.4563 - accuracy: 0.8369 - val_loss: 0.3773 - val_accuracy: 0.8661\n",
      "Epoch 11/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.4460 - accuracy: 0.8405 - val_loss: 0.3773 - val_accuracy: 0.8648\n",
      "Epoch 12/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.4381 - accuracy: 0.8425 - val_loss: 0.3685 - val_accuracy: 0.8658\n",
      "Epoch 13/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.4350 - accuracy: 0.8431 - val_loss: 0.3644 - val_accuracy: 0.8676\n",
      "Epoch 14/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.4224 - accuracy: 0.8494 - val_loss: 0.3656 - val_accuracy: 0.8677\n",
      "Epoch 15/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.4160 - accuracy: 0.8510 - val_loss: 0.3581 - val_accuracy: 0.8725\n",
      "Epoch 16/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.4098 - accuracy: 0.8534 - val_loss: 0.3610 - val_accuracy: 0.8698\n",
      "Epoch 17/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.4065 - accuracy: 0.8544 - val_loss: 0.3520 - val_accuracy: 0.8737\n",
      "Epoch 18/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.3999 - accuracy: 0.8564 - val_loss: 0.3529 - val_accuracy: 0.8733\n",
      "Epoch 19/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.3948 - accuracy: 0.8589 - val_loss: 0.3511 - val_accuracy: 0.8738\n",
      "Epoch 20/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.3951 - accuracy: 0.8558 - val_loss: 0.3480 - val_accuracy: 0.8759\n",
      "Epoch 21/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.3854 - accuracy: 0.8614 - val_loss: 0.3473 - val_accuracy: 0.8758\n",
      "Epoch 22/60\n",
      "375/375 [==============================] - 4s 9ms/step - loss: 0.3811 - accuracy: 0.8617 - val_loss: 0.3475 - val_accuracy: 0.8758\n",
      "Epoch 23/60\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 0.3771 - accuracy: 0.8640 - val_loss: 0.3421 - val_accuracy: 0.8783\n",
      "Epoch 24/60\n",
      "375/375 [==============================] - 5s 14ms/step - loss: 0.3748 - accuracy: 0.8650 - val_loss: 0.3365 - val_accuracy: 0.8795\n",
      "Epoch 25/60\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 0.3734 - accuracy: 0.8670 - val_loss: 0.3410 - val_accuracy: 0.8767\n",
      "Epoch 26/60\n",
      "375/375 [==============================] - 5s 14ms/step - loss: 0.3679 - accuracy: 0.8683 - val_loss: 0.3350 - val_accuracy: 0.8788\n",
      "Epoch 27/60\n",
      "375/375 [==============================] - 5s 14ms/step - loss: 0.3590 - accuracy: 0.8701 - val_loss: 0.3363 - val_accuracy: 0.8783\n",
      "Epoch 28/60\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 0.3605 - accuracy: 0.8699 - val_loss: 0.3334 - val_accuracy: 0.8806\n",
      "Epoch 29/60\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 0.3562 - accuracy: 0.8708 - val_loss: 0.3311 - val_accuracy: 0.8798\n",
      "Epoch 30/60\n",
      "375/375 [==============================] - 5s 14ms/step - loss: 0.3532 - accuracy: 0.8725 - val_loss: 0.3289 - val_accuracy: 0.8805\n",
      "Epoch 31/60\n",
      "375/375 [==============================] - 5s 14ms/step - loss: 0.3525 - accuracy: 0.8720 - val_loss: 0.3288 - val_accuracy: 0.8817\n",
      "Epoch 32/60\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 0.3500 - accuracy: 0.8740 - val_loss: 0.3281 - val_accuracy: 0.8817\n",
      "Epoch 33/60\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 0.3475 - accuracy: 0.8722 - val_loss: 0.3267 - val_accuracy: 0.8841\n",
      "Epoch 34/60\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 0.3421 - accuracy: 0.8763 - val_loss: 0.3204 - val_accuracy: 0.8829\n",
      "Epoch 35/60\n",
      "375/375 [==============================] - 5s 14ms/step - loss: 0.3404 - accuracy: 0.8766 - val_loss: 0.3244 - val_accuracy: 0.8822\n",
      "Epoch 36/60\n",
      "375/375 [==============================] - 6s 17ms/step - loss: 0.3404 - accuracy: 0.8765 - val_loss: 0.3203 - val_accuracy: 0.8848\n",
      "Epoch 37/60\n",
      "375/375 [==============================] - 7s 17ms/step - loss: 0.3355 - accuracy: 0.8777 - val_loss: 0.3190 - val_accuracy: 0.8835\n",
      "Epoch 38/60\n",
      "375/375 [==============================] - 8s 21ms/step - loss: 0.3333 - accuracy: 0.8800 - val_loss: 0.3204 - val_accuracy: 0.8842\n",
      "Epoch 39/60\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 0.3316 - accuracy: 0.8783 - val_loss: 0.3257 - val_accuracy: 0.8829\n",
      "Epoch 40/60\n",
      "375/375 [==============================] - 7s 19ms/step - loss: 0.3270 - accuracy: 0.8813 - val_loss: 0.3182 - val_accuracy: 0.8852\n",
      "Epoch 41/60\n",
      "375/375 [==============================] - 5s 14ms/step - loss: 0.3260 - accuracy: 0.8812 - val_loss: 0.3166 - val_accuracy: 0.8835\n",
      "Epoch 42/60\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 0.3208 - accuracy: 0.8845 - val_loss: 0.3158 - val_accuracy: 0.8863\n",
      "Epoch 43/60\n",
      "375/375 [==============================] - 5s 15ms/step - loss: 0.3223 - accuracy: 0.8816 - val_loss: 0.3173 - val_accuracy: 0.8844\n",
      "Epoch 44/60\n",
      "375/375 [==============================] - 6s 16ms/step - loss: 0.3247 - accuracy: 0.8815 - val_loss: 0.3148 - val_accuracy: 0.8863\n",
      "Epoch 45/60\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 0.3176 - accuracy: 0.8839 - val_loss: 0.3143 - val_accuracy: 0.8877\n",
      "Epoch 46/60\n",
      "375/375 [==============================] - 5s 13ms/step - loss: 0.3168 - accuracy: 0.8823 - val_loss: 0.3128 - val_accuracy: 0.8867\n",
      "Epoch 47/60\n",
      "375/375 [==============================] - 5s 14ms/step - loss: 0.3126 - accuracy: 0.8851 - val_loss: 0.3148 - val_accuracy: 0.8857\n",
      "Epoch 48/60\n",
      "375/375 [==============================] - 5s 14ms/step - loss: 0.3104 - accuracy: 0.8863 - val_loss: 0.3124 - val_accuracy: 0.8873\n",
      "Epoch 49/60\n",
      "375/375 [==============================] - 5s 14ms/step - loss: 0.3098 - accuracy: 0.8876 - val_loss: 0.3116 - val_accuracy: 0.8866\n",
      "Epoch 50/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.3045 - accuracy: 0.8879 - val_loss: 0.3133 - val_accuracy: 0.8869\n",
      "Epoch 51/60\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.3062 - accuracy: 0.8877 - val_loss: 0.3115 - val_accuracy: 0.8892\n",
      "Epoch 52/60\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.3069 - accuracy: 0.8892 - val_loss: 0.3094 - val_accuracy: 0.8882\n",
      "Epoch 53/60\n",
      "375/375 [==============================] - 4s 9ms/step - loss: 0.3028 - accuracy: 0.8879 - val_loss: 0.3133 - val_accuracy: 0.8876\n",
      "Epoch 54/60\n",
      "375/375 [==============================] - 3s 8ms/step - loss: 0.2996 - accuracy: 0.8907 - val_loss: 0.3061 - val_accuracy: 0.8882\n",
      "Epoch 55/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "375/375 [==============================] - 3s 9ms/step - loss: 0.3008 - accuracy: 0.8891 - val_loss: 0.3089 - val_accuracy: 0.8878\n",
      "Epoch 56/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.2980 - accuracy: 0.8916 - val_loss: 0.3055 - val_accuracy: 0.8882\n",
      "Epoch 57/60\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 0.2963 - accuracy: 0.8919 - val_loss: 0.3075 - val_accuracy: 0.8867\n",
      "Epoch 58/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.2940 - accuracy: 0.8913 - val_loss: 0.3046 - val_accuracy: 0.8915\n",
      "Epoch 59/60\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 0.2930 - accuracy: 0.8931 - val_loss: 0.3048 - val_accuracy: 0.8896\n",
      "Epoch 60/60\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 0.2933 - accuracy: 0.8928 - val_loss: 0.3067 - val_accuracy: 0.8898\n",
      "Epoch 1/60\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 2.0213 - accuracy: 0.3179 - val_loss: 1.0341 - val_accuracy: 0.6793\n",
      "Epoch 2/60\n",
      "375/375 [==============================] - 4s 9ms/step - loss: 1.3146 - accuracy: 0.5268 - val_loss: 0.7897 - val_accuracy: 0.7264\n",
      "Epoch 3/60\n",
      "375/375 [==============================] - 4s 12ms/step - loss: 1.0919 - accuracy: 0.6039 - val_loss: 0.7167 - val_accuracy: 0.7423\n",
      "Epoch 4/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.9803 - accuracy: 0.6408 - val_loss: 0.6757 - val_accuracy: 0.7504\n",
      "Epoch 5/60\n",
      "375/375 [==============================] - 4s 9ms/step - loss: 0.9075 - accuracy: 0.6687 - val_loss: 0.6452 - val_accuracy: 0.7617\n",
      "Epoch 6/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.8604 - accuracy: 0.6872 - val_loss: 0.6144 - val_accuracy: 0.7750\n",
      "Epoch 7/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.8234 - accuracy: 0.6988 - val_loss: 0.6042 - val_accuracy: 0.7784\n",
      "Epoch 8/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.7945 - accuracy: 0.7129 - val_loss: 0.5899 - val_accuracy: 0.7818\n",
      "Epoch 9/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.7710 - accuracy: 0.7214 - val_loss: 0.5707 - val_accuracy: 0.7923\n",
      "Epoch 10/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.7517 - accuracy: 0.7285 - val_loss: 0.5645 - val_accuracy: 0.7936\n",
      "Epoch 11/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.7331 - accuracy: 0.7356 - val_loss: 0.5601 - val_accuracy: 0.7972\n",
      "Epoch 12/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.7101 - accuracy: 0.7438 - val_loss: 0.5426 - val_accuracy: 0.8043\n",
      "Epoch 13/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.7030 - accuracy: 0.7488 - val_loss: 0.5312 - val_accuracy: 0.8103\n",
      "Epoch 14/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.6937 - accuracy: 0.7526 - val_loss: 0.5251 - val_accuracy: 0.8130\n",
      "Epoch 15/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.6806 - accuracy: 0.7569 - val_loss: 0.5240 - val_accuracy: 0.8113\n",
      "Epoch 16/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.6705 - accuracy: 0.7619 - val_loss: 0.5187 - val_accuracy: 0.8129\n",
      "Epoch 17/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.6646 - accuracy: 0.7625 - val_loss: 0.5110 - val_accuracy: 0.8178\n",
      "Epoch 18/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.6506 - accuracy: 0.7667 - val_loss: 0.5034 - val_accuracy: 0.8191\n",
      "Epoch 19/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.6425 - accuracy: 0.7716 - val_loss: 0.4986 - val_accuracy: 0.8201\n",
      "Epoch 20/60\n",
      "375/375 [==============================] - 4s 9ms/step - loss: 0.6375 - accuracy: 0.7731 - val_loss: 0.4930 - val_accuracy: 0.8228\n",
      "Epoch 21/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.6283 - accuracy: 0.7785 - val_loss: 0.4914 - val_accuracy: 0.8247\n",
      "Epoch 22/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.6252 - accuracy: 0.7777 - val_loss: 0.4856 - val_accuracy: 0.8260\n",
      "Epoch 23/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.6172 - accuracy: 0.7805 - val_loss: 0.4813 - val_accuracy: 0.8280\n",
      "Epoch 24/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.6049 - accuracy: 0.7857 - val_loss: 0.4820 - val_accuracy: 0.8247\n",
      "Epoch 25/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.6041 - accuracy: 0.7853 - val_loss: 0.4747 - val_accuracy: 0.8303\n",
      "Epoch 26/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.5940 - accuracy: 0.7894 - val_loss: 0.4626 - val_accuracy: 0.8328\n",
      "Epoch 27/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.5932 - accuracy: 0.7912 - val_loss: 0.4683 - val_accuracy: 0.8290\n",
      "Epoch 28/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.5870 - accuracy: 0.7926 - val_loss: 0.4646 - val_accuracy: 0.8307\n",
      "Epoch 29/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.5852 - accuracy: 0.7929 - val_loss: 0.4564 - val_accuracy: 0.8365\n",
      "Epoch 30/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.5808 - accuracy: 0.7966 - val_loss: 0.4574 - val_accuracy: 0.8363\n",
      "Epoch 31/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.5738 - accuracy: 0.7963 - val_loss: 0.4534 - val_accuracy: 0.8383\n",
      "Epoch 32/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.5721 - accuracy: 0.7985 - val_loss: 0.4538 - val_accuracy: 0.8383\n",
      "Epoch 33/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.5680 - accuracy: 0.8001 - val_loss: 0.4505 - val_accuracy: 0.8382\n",
      "Epoch 34/60\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 0.5600 - accuracy: 0.8029 - val_loss: 0.4452 - val_accuracy: 0.8421\n",
      "Epoch 35/60\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 0.5577 - accuracy: 0.8046 - val_loss: 0.4434 - val_accuracy: 0.8402\n",
      "Epoch 36/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.5585 - accuracy: 0.8053 - val_loss: 0.4393 - val_accuracy: 0.8443\n",
      "Epoch 37/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.5556 - accuracy: 0.8077 - val_loss: 0.4336 - val_accuracy: 0.8450\n",
      "Epoch 38/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.5526 - accuracy: 0.8066 - val_loss: 0.4356 - val_accuracy: 0.8443\n",
      "Epoch 39/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.5491 - accuracy: 0.8082 - val_loss: 0.4332 - val_accuracy: 0.8453\n",
      "Epoch 40/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.5516 - accuracy: 0.8046 - val_loss: 0.4370 - val_accuracy: 0.8416\n",
      "Epoch 41/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.5423 - accuracy: 0.8111 - val_loss: 0.4283 - val_accuracy: 0.8485\n",
      "Epoch 42/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.5362 - accuracy: 0.8108 - val_loss: 0.4270 - val_accuracy: 0.8481\n",
      "Epoch 43/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.5351 - accuracy: 0.8117 - val_loss: 0.4269 - val_accuracy: 0.8483\n",
      "Epoch 44/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.5362 - accuracy: 0.8123 - val_loss: 0.4251 - val_accuracy: 0.8493\n",
      "Epoch 45/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.5336 - accuracy: 0.8127 - val_loss: 0.4250 - val_accuracy: 0.8456\n",
      "Epoch 46/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.5303 - accuracy: 0.8156 - val_loss: 0.4241 - val_accuracy: 0.8481\n",
      "Epoch 47/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.5259 - accuracy: 0.8154 - val_loss: 0.4207 - val_accuracy: 0.8511\n",
      "Epoch 48/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.5250 - accuracy: 0.8142 - val_loss: 0.4163 - val_accuracy: 0.8512\n",
      "Epoch 49/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.5206 - accuracy: 0.8167 - val_loss: 0.4198 - val_accuracy: 0.8500\n",
      "Epoch 50/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.5178 - accuracy: 0.8188 - val_loss: 0.4160 - val_accuracy: 0.8543\n",
      "Epoch 51/60\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.5142 - accuracy: 0.8203 - val_loss: 0.4191 - val_accuracy: 0.8533\n",
      "Epoch 52/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "375/375 [==============================] - 3s 9ms/step - loss: 0.5157 - accuracy: 0.8208 - val_loss: 0.4137 - val_accuracy: 0.8524\n",
      "Epoch 53/60\n",
      "375/375 [==============================] - 4s 10ms/step - loss: 0.5171 - accuracy: 0.8199 - val_loss: 0.4177 - val_accuracy: 0.8501\n",
      "Epoch 54/60\n",
      "375/375 [==============================] - 5s 12ms/step - loss: 0.5135 - accuracy: 0.8202 - val_loss: 0.4153 - val_accuracy: 0.8521\n",
      "Epoch 55/60\n",
      "375/375 [==============================] - 4s 11ms/step - loss: 0.5130 - accuracy: 0.8205 - val_loss: 0.4153 - val_accuracy: 0.8515\n",
      "Epoch 56/60\n",
      "375/375 [==============================] - 5s 12ms/step - loss: 0.5048 - accuracy: 0.8249 - val_loss: 0.4103 - val_accuracy: 0.8518\n",
      "Epoch 57/60\n",
      "375/375 [==============================] - 4s 12ms/step - loss: 0.5043 - accuracy: 0.8225 - val_loss: 0.4078 - val_accuracy: 0.8545\n",
      "Epoch 58/60\n",
      "375/375 [==============================] - 4s 12ms/step - loss: 0.5049 - accuracy: 0.8240 - val_loss: 0.4089 - val_accuracy: 0.8547\n",
      "Epoch 59/60\n",
      "375/375 [==============================] - 4s 12ms/step - loss: 0.5024 - accuracy: 0.8224 - val_loss: 0.4072 - val_accuracy: 0.8547\n",
      "Epoch 60/60\n",
      "375/375 [==============================] - 4s 12ms/step - loss: 0.5004 - accuracy: 0.8239 - val_loss: 0.4041 - val_accuracy: 0.8572\n"
     ]
    }
   ],
   "source": [
    "history1 = model1.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    validation_split=0.2)\n",
    "\n",
    "history2 = model2.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    validation_split=0.2)\n",
    "\n",
    "history3 = model3.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3491 - accuracy: 0.8864\n",
      "0.8863999843597412\n",
      "Accuracy: 88.64%\n",
      "\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.3349 - accuracy: 0.8802\n",
      "0.8802000284194946\n",
      "Accuracy: 88.02%\n",
      "\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.4235 - accuracy: 0.8514\n",
      "0.8514000177383423\n",
      "Accuracy: 85.14%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "metrics1 = model1.evaluate(x_test, y_test) #returns loss and accuracy\n",
    "print(metrics1[1])\n",
    "print(f'Accuracy: {metrics1[1]*100:.2f}%\\n')\n",
    "\n",
    "metrics2 = model2.evaluate(x_test, y_test) #returns loss and accuracy\n",
    "print(metrics2[1])\n",
    "print(f'Accuracy: {metrics2[1]*100:.2f}%\\n')\n",
    "\n",
    "metrics3 = model3.evaluate(x_test, y_test) #returns loss and accuracy\n",
    "print(metrics3[1])\n",
    "print(f'Accuracy: {metrics3[1]*100:.2f}%\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 변화양상\n",
    "dropout은 신경망 유닛을 제거하는 것으로 overfitting을 방지할 수 있다. 1.0에 가까워지면 dropout하는 유닛 수가 적어지는 것이고 rate가 0.0에 가까워지면 dropout되는 유닛수가 많아지는 것이다. 위 예제에서 0.2, 0.5, 0.8의 rate를 살펴보면 0.8은 20%의 유닛을 제거하고 학습한 모델이고, 0.5는 반을 제거, 0.2는 80%를 제거한 것이다. 0.8부터 확인해보면 적은 수를 제거하여 overfitting이 발생해 3개의 모델 중 가장 적은 정확도를 보인다. 0.5와 0.2의 경우 0.8의 모델보다 3%정도 정확도가 나아진 모델임을 확인할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
