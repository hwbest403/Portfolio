{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "38627e5a-6418-4553-91b2-4e50d1ddd6bf",
   "metadata": {},
   "source": [
    "# ReadMe.md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c9b570c-c8f6-4c6e-a579-0dd99f07ddac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "168ecdad-64dd-4e83-926e-1502b9ccf57c",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8aee08ae-9234-4fa3-ba55-61da01b6e962",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "import os, os.path\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "import warnings\n",
    "%matplotlib inline\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "warnings.filterwarnings('ignore')\n",
    "from keras.layers import Conv2D, Activation, MaxPool2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from keras.models import Sequential\n",
    "from keras.preprocessing import image\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b302a5cb-2053-4a74-9f5a-40737fb31d42",
   "metadata": {},
   "source": [
    "# YOLO library ( Image Detect )\n",
    "---\n",
    "1. opencv로 image read\n",
    "2. useyolo함수에 img넣고 return\n",
    "3. 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1aab792a-2e12-427c-a47d-4ee196086c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Dir = \"D:/hackathon/\"\n",
    "net = cv2.dnn.readNet(Dir+\"yolov3.weights\", Dir+\"yolov3.cfg\")\n",
    "classes = []\n",
    "with open(Dir+\"coco.names\", \"r\") as f:\n",
    "    classes = [line.strip() for line in f.readlines()]\n",
    "layer_names = net.getLayerNames()\n",
    "output_layers = [layer_names[i - 1] for i in net.getUnconnectedOutLayers()]\n",
    "colors = np.random.uniform(0, 255, size=(len(classes), 3))\n",
    "\n",
    "def useyolo(img) :\n",
    "    blob = cv2.dnn.blobFromImage(img, 0.00392, (416, 416), (0, 0, 0), True, crop=False)\n",
    "    net.setInput(blob)\n",
    "    outs = net.forward(output_layers)\n",
    "    class_ids = []\n",
    "    confidences = []\n",
    "    boxes = []\n",
    "    for out in outs:\n",
    "        for detection in out:\n",
    "            scores = detection[5:]\n",
    "            class_id = np.argmax(scores)\n",
    "            confidence = scores[class_id]\n",
    "            if confidence > 0.5:\n",
    "                # Object detected\n",
    "                center_x = int(detection[0] * width)\n",
    "                center_y = int(detection[1] * height)\n",
    "                w = int(detection[2] * width)\n",
    "                h = int(detection[3] * height)\n",
    "                # 좌표\n",
    "                x = int(center_x - w / 2)\n",
    "                y = int(center_y - h / 2)\n",
    "                boxes.append([x, y, w, h])\n",
    "                confidences.append(float(confidence))\n",
    "                class_ids.append(class_id)\n",
    "    indexes = cv2.dnn.NMSBoxes(boxes, confidences, 0.5, 0.4)\n",
    "    font = cv2.FONT_HERSHEY_PLAIN\n",
    "    for i in range(len(boxes)):\n",
    "        if i in indexes:\n",
    "            x, y, w, h = boxes[i]\n",
    "            label = str(classes[class_ids[i]])\n",
    "            color = colors[i]\n",
    "            cv2.rectangle(img, (x, y), (x + w, y + h), color, 2)\n",
    "            cv2.putText(img, label, (x, y + 30), font, 3, color, 3)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cbb9806-d1f7-4f92-92da-8ff37cc4576d",
   "metadata": {},
   "source": [
    "# ProtoType ( 전체 카테고리 )\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9f55b0c2-4f8f-47c1-83f1-eedb9eed01cf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===큰 주제 : 교통===\n",
      "-소주제\n",
      "['경고음', '선박 운항', '차량 공회전', '차량 주행']\n",
      "-image\n",
      "Found 812 images belonging to 4 classes.\n",
      "Found 203 images belonging to 4 classes.\n",
      "Epoch 1/20\n",
      "40/40 [==============================] - 226s 6s/step - loss: 1.7155 - accuracy: 0.3611 - val_loss: 1.2393 - val_accuracy: 0.3850\n",
      "Epoch 2/20\n",
      "40/40 [==============================] - 167s 4s/step - loss: 0.8592 - accuracy: 0.5846 - val_loss: 0.9918 - val_accuracy: 0.5400\n",
      "Epoch 3/20\n",
      "40/40 [==============================] - 169s 4s/step - loss: 0.7376 - accuracy: 0.6288 - val_loss: 1.0144 - val_accuracy: 0.5300\n",
      "Epoch 4/20\n",
      "40/40 [==============================] - 166s 4s/step - loss: 0.6641 - accuracy: 0.6427 - val_loss: 1.4377 - val_accuracy: 0.4300\n",
      "Epoch 5/20\n",
      "40/40 [==============================] - 160s 4s/step - loss: 0.6173 - accuracy: 0.7172 - val_loss: 1.2190 - val_accuracy: 0.5050\n",
      "Epoch 6/20\n",
      "40/40 [==============================] - 162s 4s/step - loss: 0.6021 - accuracy: 0.7096 - val_loss: 1.1618 - val_accuracy: 0.5350\n",
      "Epoch 7/20\n",
      "40/40 [==============================] - 162s 4s/step - loss: 0.5547 - accuracy: 0.7412 - val_loss: 1.0498 - val_accuracy: 0.5700\n",
      "Epoch 8/20\n",
      "40/40 [==============================] - 162s 4s/step - loss: 0.5263 - accuracy: 0.7588 - val_loss: 1.1144 - val_accuracy: 0.5400\n",
      "Epoch 9/20\n",
      "40/40 [==============================] - 158s 4s/step - loss: 0.5045 - accuracy: 0.7487 - val_loss: 1.0924 - val_accuracy: 0.6850\n",
      "Epoch 10/20\n",
      "40/40 [==============================] - 160s 4s/step - loss: 0.4781 - accuracy: 0.7879 - val_loss: 1.2756 - val_accuracy: 0.5850\n",
      "Epoch 11/20\n",
      "40/40 [==============================] - 157s 4s/step - loss: 0.4207 - accuracy: 0.8056 - val_loss: 1.3914 - val_accuracy: 0.5700\n",
      "Epoch 12/20\n",
      "40/40 [==============================] - 160s 4s/step - loss: 0.4443 - accuracy: 0.8194 - val_loss: 1.0227 - val_accuracy: 0.6150\n",
      "Epoch 13/20\n",
      "40/40 [==============================] - 156s 4s/step - loss: 0.3979 - accuracy: 0.8207 - val_loss: 1.2521 - val_accuracy: 0.6750\n",
      "Epoch 14/20\n",
      "40/40 [==============================] - 157s 4s/step - loss: 0.3990 - accuracy: 0.8119 - val_loss: 1.3712 - val_accuracy: 0.6350\n",
      "Epoch 15/20\n",
      "40/40 [==============================] - 158s 4s/step - loss: 0.3297 - accuracy: 0.8561 - val_loss: 1.2636 - val_accuracy: 0.6650\n",
      "Epoch 16/20\n",
      "40/40 [==============================] - 158s 4s/step - loss: 0.4138 - accuracy: 0.8169 - val_loss: 1.2638 - val_accuracy: 0.6450\n",
      "Epoch 17/20\n",
      "40/40 [==============================] - 159s 4s/step - loss: 0.3684 - accuracy: 0.8548 - val_loss: 1.4554 - val_accuracy: 0.6500\n",
      "Epoch 18/20\n",
      "40/40 [==============================] - 151s 4s/step - loss: 0.3408 - accuracy: 0.8611 - val_loss: 1.3733 - val_accuracy: 0.7750\n",
      "Epoch 19/20\n",
      "40/40 [==============================] - 147s 4s/step - loss: 0.2954 - accuracy: 0.8674 - val_loss: 1.5119 - val_accuracy: 0.7100\n",
      "Epoch 20/20\n",
      "40/40 [==============================] - 160s 4s/step - loss: 0.3181 - accuracy: 0.8699 - val_loss: 1.2806 - val_accuracy: 0.7100\n",
      "===큰 주제 : 농기계===\n",
      "-소주제\n",
      "['경운기 작업', '분무기 작업', '스프링클러 동작', '양수기 동작', '예초기 작업', '콤바인 작업', '트랙터 작업']\n",
      "-image\n",
      "Found 1040 images belonging to 7 classes.\n",
      "Found 258 images belonging to 7 classes.\n",
      "Epoch 1/20\n",
      "51/51 [==============================] - 206s 4s/step - loss: 2.0152 - accuracy: 0.3118 - val_loss: 1.7278 - val_accuracy: 0.2833\n",
      "Epoch 2/20\n",
      "51/51 [==============================] - 151s 3s/step - loss: 1.1005 - accuracy: 0.5961 - val_loss: 1.0992 - val_accuracy: 0.6042\n",
      "Epoch 3/20\n",
      "51/51 [==============================] - 163s 3s/step - loss: 0.8548 - accuracy: 0.6804 - val_loss: 1.1893 - val_accuracy: 0.5000\n",
      "Epoch 4/20\n",
      "51/51 [==============================] - 152s 3s/step - loss: 0.7419 - accuracy: 0.7235 - val_loss: 1.1625 - val_accuracy: 0.5958\n",
      "Epoch 5/20\n",
      "51/51 [==============================] - 151s 3s/step - loss: 0.6577 - accuracy: 0.7382 - val_loss: 0.9998 - val_accuracy: 0.5958\n",
      "Epoch 6/20\n",
      "51/51 [==============================] - 151s 3s/step - loss: 0.5568 - accuracy: 0.7990 - val_loss: 1.0788 - val_accuracy: 0.5500\n",
      "Epoch 7/20\n",
      "51/51 [==============================] - 151s 3s/step - loss: 0.5717 - accuracy: 0.7873 - val_loss: 0.9079 - val_accuracy: 0.6250\n",
      "Epoch 8/20\n",
      "51/51 [==============================] - 151s 3s/step - loss: 0.4843 - accuracy: 0.8333 - val_loss: 0.8491 - val_accuracy: 0.6583\n",
      "Epoch 9/20\n",
      "51/51 [==============================] - 151s 3s/step - loss: 0.4288 - accuracy: 0.8490 - val_loss: 0.9382 - val_accuracy: 0.5958\n",
      "Epoch 10/20\n",
      "51/51 [==============================] - 151s 3s/step - loss: 0.3639 - accuracy: 0.8755 - val_loss: 0.8264 - val_accuracy: 0.6833\n",
      "Epoch 11/20\n",
      "51/51 [==============================] - 151s 3s/step - loss: 0.3656 - accuracy: 0.8676 - val_loss: 0.8542 - val_accuracy: 0.6417\n",
      "Epoch 12/20\n",
      "51/51 [==============================] - 151s 3s/step - loss: 0.2919 - accuracy: 0.8922 - val_loss: 0.8670 - val_accuracy: 0.6667\n",
      "Epoch 13/20\n",
      "51/51 [==============================] - 151s 3s/step - loss: 0.2628 - accuracy: 0.9157 - val_loss: 0.7944 - val_accuracy: 0.7333\n",
      "Epoch 14/20\n",
      "51/51 [==============================] - 152s 3s/step - loss: 0.2878 - accuracy: 0.8971 - val_loss: 0.6363 - val_accuracy: 0.7417\n",
      "Epoch 15/20\n",
      "51/51 [==============================] - 151s 3s/step - loss: 0.2606 - accuracy: 0.9137 - val_loss: 0.6528 - val_accuracy: 0.7083\n",
      "Epoch 16/20\n",
      "51/51 [==============================] - 151s 3s/step - loss: 0.2608 - accuracy: 0.9078 - val_loss: 0.6507 - val_accuracy: 0.7583\n",
      "Epoch 17/20\n",
      "51/51 [==============================] - 153s 3s/step - loss: 0.2367 - accuracy: 0.9167 - val_loss: 0.5711 - val_accuracy: 0.7708\n",
      "Epoch 18/20\n",
      "51/51 [==============================] - 155s 3s/step - loss: 0.2313 - accuracy: 0.9167 - val_loss: 0.7321 - val_accuracy: 0.7833\n",
      "Epoch 19/20\n",
      "51/51 [==============================] - 151s 3s/step - loss: 0.2810 - accuracy: 0.9029 - val_loss: 0.6858 - val_accuracy: 0.8042\n",
      "Epoch 20/20\n",
      "51/51 [==============================] - 151s 3s/step - loss: 0.2215 - accuracy: 0.9176 - val_loss: 0.7432 - val_accuracy: 0.7708\n",
      "===큰 주제 : 생활가전===\n",
      "-소주제\n",
      "['냉장고 사용', '드라이어 사용', '면도하기', '면도하기(전동)', '믹서기 갈기', '선풍기 사용', '세탁기', '안마하기', '안마하기(전동)', '압력밥솥 사용', '에어컨 사용', '이발하기', '전자레인지 사용', '주전자 사용', '청소하기', '캐리어 사용', '커피 내리기', '커피콩 갈기', '커피콩 볶기', '키보드 치기']\n",
      "-image\n",
      "Found 3985 images belonging to 20 classes.\n",
      "Found 993 images belonging to 20 classes.\n",
      "Epoch 1/20\n",
      "199/199 [==============================] - 721s 4s/step - loss: 2.9720 - accuracy: 0.0908 - val_loss: 2.8678 - val_accuracy: 0.1459\n",
      "Epoch 2/20\n",
      "199/199 [==============================] - 563s 3s/step - loss: 2.5594 - accuracy: 0.2237 - val_loss: 2.7505 - val_accuracy: 0.3194\n",
      "Epoch 3/20\n",
      "199/199 [==============================] - 564s 3s/step - loss: 2.1106 - accuracy: 0.3729 - val_loss: 2.5155 - val_accuracy: 0.3122\n",
      "Epoch 4/20\n",
      "199/199 [==============================] - 563s 3s/step - loss: 1.7982 - accuracy: 0.4509 - val_loss: 2.4160 - val_accuracy: 0.3837\n",
      "Epoch 5/20\n",
      "199/199 [==============================] - 562s 3s/step - loss: 1.6332 - accuracy: 0.5042 - val_loss: 2.4931 - val_accuracy: 0.4010\n",
      "Epoch 6/20\n",
      "199/199 [==============================] - 564s 3s/step - loss: 1.4685 - accuracy: 0.5498 - val_loss: 2.4171 - val_accuracy: 0.4449\n",
      "Epoch 7/20\n",
      "199/199 [==============================] - 562s 3s/step - loss: 1.3395 - accuracy: 0.5854 - val_loss: 2.1450 - val_accuracy: 0.4714\n",
      "Epoch 8/20\n",
      "199/199 [==============================] - 562s 3s/step - loss: 1.2229 - accuracy: 0.6361 - val_loss: 2.3474 - val_accuracy: 0.4714\n",
      "Epoch 9/20\n",
      "199/199 [==============================] - 562s 3s/step - loss: 1.1064 - accuracy: 0.6588 - val_loss: 2.3146 - val_accuracy: 0.4990\n",
      "Epoch 10/20\n",
      "199/199 [==============================] - 563s 3s/step - loss: 1.0409 - accuracy: 0.6835 - val_loss: 2.4375 - val_accuracy: 0.5327\n",
      "Epoch 11/20\n",
      "199/199 [==============================] - 563s 3s/step - loss: 0.9152 - accuracy: 0.7160 - val_loss: 2.1593 - val_accuracy: 0.5643\n",
      "Epoch 12/20\n",
      "199/199 [==============================] - 564s 3s/step - loss: 0.8219 - accuracy: 0.7511 - val_loss: 2.9329 - val_accuracy: 0.5296\n",
      "Epoch 13/20\n",
      "199/199 [==============================] - 564s 3s/step - loss: 0.8186 - accuracy: 0.7475 - val_loss: 2.1351 - val_accuracy: 0.5735\n",
      "Epoch 14/20\n",
      "199/199 [==============================] - 563s 3s/step - loss: 0.7668 - accuracy: 0.7723 - val_loss: 2.0130 - val_accuracy: 0.5847\n",
      "Epoch 15/20\n",
      "199/199 [==============================] - 562s 3s/step - loss: 0.6891 - accuracy: 0.7904 - val_loss: 2.2017 - val_accuracy: 0.6133\n",
      "Epoch 16/20\n",
      "199/199 [==============================] - 564s 3s/step - loss: 0.6630 - accuracy: 0.7987 - val_loss: 2.4115 - val_accuracy: 0.5929\n",
      "Epoch 17/20\n",
      "199/199 [==============================] - 565s 3s/step - loss: 0.6341 - accuracy: 0.8058 - val_loss: 2.2395 - val_accuracy: 0.5908\n",
      "Epoch 18/20\n",
      "199/199 [==============================] - 563s 3s/step - loss: 0.5524 - accuracy: 0.8267 - val_loss: 2.1770 - val_accuracy: 0.6204\n",
      "Epoch 19/20\n",
      "199/199 [==============================] - 564s 3s/step - loss: 0.5403 - accuracy: 0.8414 - val_loss: 2.1363 - val_accuracy: 0.6143\n",
      "Epoch 20/20\n",
      "199/199 [==============================] - 562s 3s/step - loss: 0.4934 - accuracy: 0.8494 - val_loss: 1.9957 - val_accuracy: 0.6439\n",
      "===큰 주제 : 요리===\n",
      "-소주제\n",
      "['굽기', '깎기', '끓이기', '다지기(고기)', '다지기(채소)', '따르기', '무치기', '썰기', '전 부치기', '탄산 따르기', '튀기기']\n",
      "-image\n",
      "Found 2535 images belonging to 11 classes.\n",
      "Found 633 images belonging to 11 classes.\n",
      "Epoch 1/20\n",
      "126/126 [==============================] - 481s 4s/step - loss: 2.2326 - accuracy: 0.1948 - val_loss: 2.1654 - val_accuracy: 0.2339\n",
      "Epoch 2/20\n",
      "126/126 [==============================] - 363s 3s/step - loss: 1.8563 - accuracy: 0.3539 - val_loss: 2.0998 - val_accuracy: 0.2661\n",
      "Epoch 3/20\n",
      "126/126 [==============================] - 363s 3s/step - loss: 1.6659 - accuracy: 0.3893 - val_loss: 2.0968 - val_accuracy: 0.3000\n",
      "Epoch 4/20\n",
      "126/126 [==============================] - 362s 3s/step - loss: 1.4135 - accuracy: 0.5109 - val_loss: 2.1462 - val_accuracy: 0.3403\n",
      "Epoch 5/20\n",
      "126/126 [==============================] - 363s 3s/step - loss: 1.1920 - accuracy: 0.5952 - val_loss: 1.6864 - val_accuracy: 0.4355\n",
      "Epoch 6/20\n",
      "126/126 [==============================] - 363s 3s/step - loss: 1.0290 - accuracy: 0.6441 - val_loss: 1.6883 - val_accuracy: 0.4952\n",
      "Epoch 7/20\n",
      "126/126 [==============================] - 363s 3s/step - loss: 0.8774 - accuracy: 0.6990 - val_loss: 1.5874 - val_accuracy: 0.5452\n",
      "Epoch 8/20\n",
      "126/126 [==============================] - 363s 3s/step - loss: 0.8059 - accuracy: 0.7268 - val_loss: 1.9872 - val_accuracy: 0.5097\n",
      "Epoch 9/20\n",
      "126/126 [==============================] - 363s 3s/step - loss: 0.7478 - accuracy: 0.7471 - val_loss: 1.6811 - val_accuracy: 0.6032\n",
      "Epoch 10/20\n",
      "126/126 [==============================] - 362s 3s/step - loss: 0.6447 - accuracy: 0.7813 - val_loss: 1.8039 - val_accuracy: 0.5452\n",
      "Epoch 11/20\n",
      "126/126 [==============================] - 363s 3s/step - loss: 0.5763 - accuracy: 0.8163 - val_loss: 1.6621 - val_accuracy: 0.6226\n",
      "Epoch 12/20\n",
      "126/126 [==============================] - 363s 3s/step - loss: 0.5656 - accuracy: 0.8020 - val_loss: 1.7592 - val_accuracy: 0.6177\n",
      "Epoch 13/20\n",
      "126/126 [==============================] - 363s 3s/step - loss: 0.5436 - accuracy: 0.8171 - val_loss: 1.6931 - val_accuracy: 0.5774\n",
      "Epoch 14/20\n",
      "126/126 [==============================] - 363s 3s/step - loss: 0.4770 - accuracy: 0.8382 - val_loss: 1.4670 - val_accuracy: 0.6258\n",
      "Epoch 15/20\n",
      "126/126 [==============================] - 363s 3s/step - loss: 0.4370 - accuracy: 0.8513 - val_loss: 1.8852 - val_accuracy: 0.6452\n",
      "Epoch 16/20\n",
      "126/126 [==============================] - 363s 3s/step - loss: 0.4340 - accuracy: 0.8573 - val_loss: 1.3773 - val_accuracy: 0.6694\n",
      "Epoch 17/20\n",
      "126/126 [==============================] - 363s 3s/step - loss: 0.3628 - accuracy: 0.8751 - val_loss: 1.5388 - val_accuracy: 0.6823\n",
      "Epoch 18/20\n",
      "126/126 [==============================] - 363s 3s/step - loss: 0.3827 - accuracy: 0.8660 - val_loss: 1.8342 - val_accuracy: 0.6032\n",
      "Epoch 19/20\n",
      "126/126 [==============================] - 363s 3s/step - loss: 0.3351 - accuracy: 0.8835 - val_loss: 1.6818 - val_accuracy: 0.6194\n",
      "Epoch 20/20\n",
      "126/126 [==============================] - 363s 3s/step - loss: 0.3466 - accuracy: 0.8938 - val_loss: 1.8556 - val_accuracy: 0.6823\n",
      "===큰 주제 : 운동===\n",
      "-소주제\n",
      "['골프 치기', '당구 치기', '러닝머신 운동하기', '볼링 치기', '자전거 타기', '탁구 치기']\n",
      "-image\n",
      "Found 1440 images belonging to 6 classes.\n",
      "Found 360 images belonging to 6 classes.\n",
      "Epoch 1/20\n",
      "72/72 [==============================] - 309s 4s/step - loss: 0.8142 - accuracy: 0.6924 - val_loss: 0.3592 - val_accuracy: 0.8917\n",
      "Epoch 2/20\n",
      "72/72 [==============================] - 243s 3s/step - loss: 0.2504 - accuracy: 0.9222 - val_loss: 0.3629 - val_accuracy: 0.9056\n",
      "Epoch 3/20\n",
      "72/72 [==============================] - 243s 3s/step - loss: 0.1691 - accuracy: 0.9479 - val_loss: 0.3001 - val_accuracy: 0.9056\n",
      "Epoch 4/20\n",
      "72/72 [==============================] - 243s 3s/step - loss: 0.2227 - accuracy: 0.9285 - val_loss: 0.4655 - val_accuracy: 0.8861\n",
      "Epoch 5/20\n",
      "72/72 [==============================] - 243s 3s/step - loss: 0.1339 - accuracy: 0.9549 - val_loss: 0.5367 - val_accuracy: 0.9000\n",
      "Epoch 6/20\n",
      "72/72 [==============================] - 245s 3s/step - loss: 0.0968 - accuracy: 0.9632 - val_loss: 0.3530 - val_accuracy: 0.9222\n",
      "Epoch 7/20\n",
      "72/72 [==============================] - 245s 3s/step - loss: 0.0653 - accuracy: 0.9771 - val_loss: 0.4837 - val_accuracy: 0.9111\n",
      "Epoch 8/20\n",
      "72/72 [==============================] - 243s 3s/step - loss: 0.0983 - accuracy: 0.9618 - val_loss: 0.5180 - val_accuracy: 0.9028\n",
      "Epoch 9/20\n",
      "72/72 [==============================] - 243s 3s/step - loss: 0.0806 - accuracy: 0.9646 - val_loss: 0.4348 - val_accuracy: 0.8889\n",
      "Epoch 10/20\n",
      "72/72 [==============================] - 246s 3s/step - loss: 0.1452 - accuracy: 0.9535 - val_loss: 0.5845 - val_accuracy: 0.9000\n",
      "Epoch 11/20\n",
      "72/72 [==============================] - 244s 3s/step - loss: 0.0992 - accuracy: 0.9681 - val_loss: 0.2410 - val_accuracy: 0.9417\n",
      "Epoch 12/20\n",
      "72/72 [==============================] - 243s 3s/step - loss: 0.0685 - accuracy: 0.9771 - val_loss: 0.3545 - val_accuracy: 0.9417\n",
      "Epoch 13/20\n",
      "72/72 [==============================] - 244s 3s/step - loss: 0.0887 - accuracy: 0.9729 - val_loss: 0.3180 - val_accuracy: 0.9389\n",
      "Epoch 14/20\n",
      "72/72 [==============================] - 243s 3s/step - loss: 0.0586 - accuracy: 0.9785 - val_loss: 0.2888 - val_accuracy: 0.9472\n",
      "Epoch 15/20\n",
      "72/72 [==============================] - 244s 3s/step - loss: 0.0372 - accuracy: 0.9903 - val_loss: 0.2665 - val_accuracy: 0.9556\n",
      "Epoch 16/20\n",
      "72/72 [==============================] - 243s 3s/step - loss: 0.0982 - accuracy: 0.9639 - val_loss: 0.3339 - val_accuracy: 0.9278\n",
      "Epoch 17/20\n",
      "72/72 [==============================] - 243s 3s/step - loss: 0.0400 - accuracy: 0.9854 - val_loss: 0.4890 - val_accuracy: 0.9194\n",
      "Epoch 18/20\n",
      "72/72 [==============================] - 243s 3s/step - loss: 0.2253 - accuracy: 0.9340 - val_loss: 0.2235 - val_accuracy: 0.9694\n",
      "Epoch 19/20\n",
      "72/72 [==============================] - 243s 3s/step - loss: 0.0618 - accuracy: 0.9799 - val_loss: 0.3091 - val_accuracy: 0.9472\n",
      "Epoch 20/20\n",
      "72/72 [==============================] - 243s 3s/step - loss: 0.0519 - accuracy: 0.9819 - val_loss: 0.4240 - val_accuracy: 0.9056\n",
      "===큰 주제 : 전통===\n",
      "-소주제\n",
      "['괘종시계 작동', '교회 종', '다듬이질', '대패질', '떡메질', '맷돌 갈기', '먹 갈기', '물레방아 돌기', '불 지피기', '석유풍로 사용', '숫돌 갈기', '식당 벨', '싸리비 질', '엿장수', '작두질', '절구질', '초인종', '키질', '타자 치기', '프론트 벨', '학교 차임벨', '화투치기', '확독 갈기', '횃불 지피기']\n",
      "-image\n",
      "Found 4172 images belonging to 24 classes.\n",
      "Found 1037 images belonging to 24 classes.\n",
      "Epoch 1/20\n",
      "208/208 [==============================] - 840s 4s/step - loss: 2.4789 - accuracy: 0.2558 - val_loss: 2.0342 - val_accuracy: 0.3790\n",
      "Epoch 2/20\n",
      "208/208 [==============================] - 771s 4s/step - loss: 1.4613 - accuracy: 0.5588 - val_loss: 1.5255 - val_accuracy: 0.5352\n",
      "Epoch 3/20\n",
      "208/208 [==============================] - 775s 4s/step - loss: 1.0085 - accuracy: 0.6934 - val_loss: 1.2120 - val_accuracy: 0.6355\n",
      "Epoch 4/20\n",
      "208/208 [==============================] - 778s 4s/step - loss: 0.8074 - accuracy: 0.7587 - val_loss: 1.0599 - val_accuracy: 0.7252\n",
      "Epoch 5/20\n",
      "208/208 [==============================] - 775s 4s/step - loss: 0.6050 - accuracy: 0.8145 - val_loss: 1.0877 - val_accuracy: 0.6779\n",
      "Epoch 6/20\n",
      "208/208 [==============================] - 789s 4s/step - loss: 0.5284 - accuracy: 0.8420 - val_loss: 0.8632 - val_accuracy: 0.7512\n",
      "Epoch 7/20\n",
      "208/208 [==============================] - 785s 4s/step - loss: 0.4473 - accuracy: 0.8642 - val_loss: 0.8637 - val_accuracy: 0.7695\n",
      "Epoch 8/20\n",
      "208/208 [==============================] - 801s 4s/step - loss: 0.4286 - accuracy: 0.8692 - val_loss: 0.8280 - val_accuracy: 0.7743\n",
      "Epoch 9/20\n",
      "208/208 [==============================] - 796s 4s/step - loss: 0.3516 - accuracy: 0.8974 - val_loss: 0.7360 - val_accuracy: 0.7734\n",
      "Epoch 10/20\n",
      "208/208 [==============================] - 792s 4s/step - loss: 0.3136 - accuracy: 0.9013 - val_loss: 1.0950 - val_accuracy: 0.7184\n",
      "Epoch 11/20\n",
      "208/208 [==============================] - 803s 4s/step - loss: 0.3445 - accuracy: 0.8926 - val_loss: 0.6863 - val_accuracy: 0.8110\n",
      "Epoch 12/20\n",
      "208/208 [==============================] - 797s 4s/step - loss: 0.2775 - accuracy: 0.9171 - val_loss: 0.7408 - val_accuracy: 0.8110\n",
      "Epoch 13/20\n",
      "208/208 [==============================] - 787s 4s/step - loss: 0.2473 - accuracy: 0.9205 - val_loss: 0.7559 - val_accuracy: 0.8149\n",
      "Epoch 14/20\n",
      "208/208 [==============================] - 783s 4s/step - loss: 0.2586 - accuracy: 0.9208 - val_loss: 0.9344 - val_accuracy: 0.7965\n",
      "Epoch 15/20\n",
      "208/208 [==============================] - 789s 4s/step - loss: 0.2500 - accuracy: 0.9184 - val_loss: 0.6790 - val_accuracy: 0.8274\n",
      "Epoch 16/20\n",
      "208/208 [==============================] - 799s 4s/step - loss: 0.2221 - accuracy: 0.9302 - val_loss: 1.0648 - val_accuracy: 0.7387\n",
      "Epoch 17/20\n",
      "208/208 [==============================] - 795s 4s/step - loss: 0.2217 - accuracy: 0.9323 - val_loss: 0.7264 - val_accuracy: 0.8235\n",
      "Epoch 18/20\n",
      "208/208 [==============================] - 795s 4s/step - loss: 0.2037 - accuracy: 0.9311 - val_loss: 0.8214 - val_accuracy: 0.8206\n",
      "Epoch 19/20\n",
      "208/208 [==============================] - 792s 4s/step - loss: 0.1793 - accuracy: 0.9439 - val_loss: 0.7018 - val_accuracy: 0.8235\n",
      "Epoch 20/20\n",
      "208/208 [==============================] - 795s 4s/step - loss: 0.1822 - accuracy: 0.9468 - val_loss: 0.7578 - val_accuracy: 0.8226\n"
     ]
    }
   ],
   "source": [
    "img_dir = 'D:/hackathon/이미지사운드매칭_해커톤_데이터셋/이미지/원천데이터/'\n",
    "for b_cate in os.listdir(img_dir) :\n",
    "    print(f\"===큰 주제 : {b_cate}===\")\n",
    "    print(\"-소주제\")\n",
    "    s_label = list()\n",
    "    f_cnt = 0\n",
    "    for s_cate in os.listdir(img_dir+b_cate+'/') :\n",
    "        s_label.append(s_cate)\n",
    "        f_cnt += len(os.listdir(img_dir+b_cate+'/'+s_cate+'/'))\n",
    "    print(s_label)\n",
    "    print(\"-image\")\n",
    "    datagen=ImageDataGenerator(rescale=1./255,\n",
    "                               rotation_range=40,\n",
    "                               width_shift_range=0.2,\n",
    "                               height_shift_range=0.2,\n",
    "                               shear_range=0.2,\n",
    "                               zoom_range=0.2,\n",
    "                               horizontal_flip=True,\n",
    "                               fill_mode='nearest',\n",
    "                               validation_split=0.2)\n",
    "    train_dataset = datagen.flow_from_directory(directory=img_dir+b_cate+'/',\n",
    "                                                 shuffle=True,\n",
    "                                                 target_size=(150, 150), \n",
    "                                                 subset=\"training\",\n",
    "                                                 class_mode='categorical',\n",
    "                                               batch_size=20)\n",
    "    validation_dataset = datagen.flow_from_directory(directory=img_dir+b_cate+'/',\n",
    "                                                 shuffle=True,\n",
    "                                                 target_size=(150, 150), \n",
    "                                                 subset=\"validation\",\n",
    "                                                 class_mode='categorical',\n",
    "                                                    batch_size=20)\n",
    "    \n",
    "#     print(f_cnt-(f_cnt//5), f_cnt//5)\n",
    "#     continue\n",
    "    model = keras.Sequential()\n",
    "    model.add(keras.layers.Conv2D(32, kernel_size=(3,3),activation='relu',input_shape=(150,150,3)))\n",
    "    model.add(keras.layers.MaxPooling2D(2,2))\n",
    "    model.add(keras.layers.Dropout(0.2))\n",
    "\n",
    "    model.add(keras.layers.Conv2D(64, kernel_size=(3,3),activation='relu'))\n",
    "    model.add(keras.layers.MaxPooling2D(2,2))\n",
    "    model.add(keras.layers.Conv2D(64, kernel_size=(3,3),activation='relu'))\n",
    "    model.add(keras.layers.MaxPooling2D(2,2))\n",
    "    model.add(keras.layers.Dropout(0.2))\n",
    "\n",
    "    model.add(keras.layers.Flatten())\n",
    "    model.add(keras.layers.Dense(512,activation='relu'))\n",
    "    model.add(keras.layers.Dense(len(s_label),activation='softmax'))\n",
    "    model.compile(optimizer='adam',loss='categorical_crossentropy',metrics='accuracy')\n",
    "    with tf.device(\"/device:GPU:0\") :\n",
    "        model.fit_generator(train_dataset,\n",
    "                           steps_per_epoch=(f_cnt-(f_cnt//5))//20,\n",
    "                           validation_data=validation_dataset,\n",
    "                           epochs=20,\n",
    "                           validation_steps=(f_cnt//5)//20)\n",
    "    model.save_weights(b_cate+'.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4091e8b9-b5e1-4d90-aaea-d38721fb5a0b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
